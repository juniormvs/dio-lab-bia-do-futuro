import pandas as pd
import json
import time
from dotenv import load_dotenv, find_dotenv
from groq import Groq
import streamlit as st
import os

load_dotenv(find_dotenv())

client = Groq(
    #Chama a api_key do arquivo .env
    api_key=os.environ.get('GROQ_API')#
)

print(type(Groq))

#1. Carregando os dados
historico = pd.read_csv('data/historico_atendimento.csv')
transacoes = pd.read_csv('data/transacoes.csv')
with open('data/perfil_investidor.json', 'r', encoding='utf-8') as f:
    perfil = json.load(f)
with open('data/produtos_financeiros.json', 'r', encoding='utf-8') as f:
    produtos = json.load(f)


#2. Montando Contexto
CONTEXTO = f"""
CLIENTE: {perfil['nome']}, {perfil['idade']} anos, perfil {perfil['perfil_investidor']}
OBJETIVO: {perfil['objetivo_principal']}
PATRIM√îNIO R$: {perfil['patrimonio_total']} | RESERVA: R$ {perfil['reserva_emergencia_atual']}

TRANSA√á√ïES RECENTES:
{transacoes.to_string(index=False)}

ATENDIMENTOS ANTERIORES:
{historico.to_string(index=False)}

PRODUTOS DISPON√çVEIS:
{json.dumps(produtos, indent=2, ensure_ascii=False)}
"""

#3. SYSTEM PROMPT
PROMPT = """
Voc√™ √© um agente financeiro especializado em investimentos de baixo e m√©dio risco.

OBJETIVO: Ensinar economia e indicar investimentos conforme dados fornecidos.

Regras:
NUNCA inventar informa√ß√µes.
Responder apenas sobre finan√ßas, mercado financeiro e investimentos.
Usar somente dados fornecidos pelo usu√°rio.
Se n√£o souber, admitir e sugerir alternativas financeiras.
Sempre dar dicas pr√°ticas ap√≥s explica√ß√µes.
Indicar investimentos apenas com base nos dados do usu√°rio.
Responder em at√© 3 par√°grafos, de forma clara e direta.
Fora do escopo ‚Üí informar que s√≥ trata de finan√ßas.
Pedidos sens√≠veis (senhas, dados pessoais) ‚Üí recusar.
Recomenda√ß√µes sem contexto ‚Üí pedir perfil do investidor antes.
"""
#4. Inicilizar o hist√≥rico na sess√£o
if 'chat_history' not in st.session_state:
     st.session_state.chat_history = []
    
#5. Interface Streamlit
st.title('Agente financeiro Inteligente üíπ')

#6. Mostrar hist√≥rico

for msg in st.session_state.chat_history:
    if msg['role'] == 'user':
          st.markdown(f'**Voc√™:** {msg["content"]}')
    else:
     st.markdown(f'**Agente:** {msg["content"]}')

#6. Campo de entrada
USER_QUESTION = st.text_input('Digite sua pergunta:')
if USER_QUESTION:
    start_time = time.time()
    st.session_state.chat_history.append({'role':'user', 'content': USER_QUESTION})

     #Montar mensagens (prompt+contexto+hist√≥rico+nova_pergunta)
    messages = [{'role':'system', 'content':PROMPT},
                 {'role':'user', 'content': CONTEXTO}] + st.session_state.chat_history
     
     #Chamada ao Groq
    chat_completion = client.chat.completions.create(
          model='openai/gpt-oss-120b',
          messages=messages,
          temperature=0.2
     )
    latencia = time.time() - start_time
    resposta = chat_completion.choices[0].message.content

    #Adicionar resposta ao hist√≥rico
    st.session_state.chat_history.append({'role':'assistant', 'content': resposta})

    #Mostrar resposta
    st.subheader('Resposta do Agente:')
    st.write(resposta)

    #M√©tricas
    st.markdown('### M√©tricas da chamada')
    st.write(f'‚è± Lat√™ncia: {latencia:.2f} segundos')
    st.write(f'Tokens prompt: {chat_completion.usage.prompt_tokens}')
    st.write(f'Tokens resposta: {chat_completion.usage.completion_tokens}')
    st.write(f'Token totais: {chat_completion.usage.total_tokens}')
